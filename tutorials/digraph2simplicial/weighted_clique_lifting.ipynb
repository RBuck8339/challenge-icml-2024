{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from modules.data.load.loaders import GraphLoader\n",
    "from modules.data.preprocess.preprocessor import PreProcessor\n",
    "from modules.utils.utils import (\n",
    "    describe_data,\n",
    "    load_dataset_config,\n",
    "    load_model_config,\n",
    "    load_transform_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset configuration for Ethereum:\n",
      "\n",
      "{'data_domain': 'graph',\n",
      " 'data_type': 'Transactions',\n",
      " 'data_name': 'EthereumTokenNetwork',\n",
      " 'data_dir': 'datasets/Transactions/EthereumTokenNetwork',\n",
      " 'num_features': 1,\n",
      " 'num_classes': 5,\n",
      " 'task': 'classification',\n",
      " 'loss_type': 'cross_entropy',\n",
      " 'task_level': 'graph'}\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Ethereum\"\n",
    "dataset_config = load_dataset_config(dataset_name)\n",
    "loader = GraphLoader(dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/ronan/Downloads/GitHub/challenge-icml-2024/datasets/Transactions/EthereumTokenNetwork/EthereumTokenNetwork.pt\n",
      "\n",
      "Dataset only contains 1 sample:\n",
      " - Graph with 47052 vertices and 79722 edges.\n",
      " - Features dimensions: [1, 0]\n",
      " - There are 32686 isolated nodes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = loader.load()\n",
    "describe_data(dataset, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Apply Lifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transform configuration for digraph2simplicial/weighted_clique_lifting:\n",
      "\n",
      "{'transform_type': 'lifting',\n",
      " 'transform_name': 'WeightedSimplicialCliqueLifting',\n",
      " 'complex_dim': 3,\n",
      " 'preserve_edge_attr': True,\n",
      " 'signed': True,\n",
      " 'feature_lifting': 'ProjectionSum'}\n"
     ]
    }
   ],
   "source": [
    "# Define transformation type and id\n",
    "transform_type = \"liftings\"\n",
    "# If the transform is a topological lifting, it should include both the type of the lifting and the identifier\n",
    "transform_id = \"digraph2simplicial/weighted_clique_lifting\"\n",
    "\n",
    "# Read yaml file\n",
    "transform_config = {\"lifting\": load_transform_config(transform_type, transform_id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifted_dataset = PreProcessor(dataset, transform_config, loader.data_dir)\n",
    "describe_data(lifted_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and Run the Simplicial NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models.simplicial.san import SANModel\n",
    "\n",
    "model_type = \"simplicial\"\n",
    "model_id = \"san\"\n",
    "model_config = load_model_config(model_type, model_id)  # I need to look at this\n",
    "\n",
    "model = SANModel(model_config, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify this works for one pass then actually create a full model if we want to\n",
    "y_hat = model(lifted_dataset.get(0))\n",
    "print(y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
